{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DEEP LEARNING COURSE PROJECT (IMAGE CLASSIFICATION)**\n",
        "\n",
        "### **NAME:** ANISH SRIRAM B S\n",
        "### **SCHOOL:** SCDS\n",
        "### **EMAIL:** anishsriram.b-26@scds.saiuniversity.edu.in"
      ],
      "metadata": {
        "id": "JjVRTQN-9A58"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRANSFER LEARNING - RESNET101V2 MODEL"
      ],
      "metadata": {
        "id": "aOl2HIkT9Cwc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LOADING THE DATASET"
      ],
      "metadata": {
        "id": "hpgSmatS9rw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Details:\n",
        "\n",
        "*   Total Number of Images in the Dataset: 1661\n",
        "*   Number of Images present per class:\n",
        "    *   Number of Images in Motorbikes: 500\n",
        "    *   Number of Images in Airplanes: 500\n",
        "    *   Number of Images in Schooner: 63\n",
        "*   Total Number of Images used for Training and Testing: 1063\n",
        "    *   Number of Images used for Training: 797\n",
        "    *   Number of Images used for Testing: 266\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Xtfg3nlZzl3p"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PcmfWmB681pj"
      },
      "outputs": [],
      "source": [
        "# Importing necessary modules\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import PIL\n",
        "from PIL import Image\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "from numpy import save\n",
        "from numpy import load"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VAYztip99f1R",
        "outputId": "ac294ff5-00fd-441e-a467-cb46ca45da5d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the dataset which is already processed\n",
        "X_train_std = load('/content/drive/MyDrive/Deep Learning Project/Dataset/X_train_std.npy')\n",
        "X_test_std = load('/content/drive/MyDrive/Deep Learning Project/Dataset/X_test_std.npy')\n",
        "y_train = load('/content/drive/MyDrive/Deep Learning Project/Dataset/y_train.npy')\n",
        "y_test = load('/content/drive/MyDrive/Deep Learning Project/Dataset/y_test.npy')\n",
        "\n",
        "print(\"X_train_std_shape:\",X_train_std.shape)\n",
        "print(\"X_test_std_shape:\",X_test_std.shape)\n",
        "print(\"y_train_shape:\",y_train.shape)\n",
        "print(\"y_test_shape:\",y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW8l4dOg9kGO",
        "outputId": "7bf2a613-f91e-487d-aab2-86b5b25e5a3b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train_std_shape: (797, 299, 299, 3)\n",
            "X_test_std_shape: (266, 299, 299, 3)\n",
            "y_train_shape: (797,)\n",
            "y_test_shape: (266,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TRANSFER LEARNING"
      ],
      "metadata": {
        "id": "0ChkupG39wyM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading the feature extractor part of the ResNet101V2 model\n",
        "base_model = keras.applications.ResNet101V2(weights='imagenet',include_top=False)\n",
        "\n",
        "# Setting the weights of the feature extractor part as non trainable\n",
        "for layer in base_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Defining the classifier part\n",
        "global_avg_pooling = keras.layers.GlobalAveragePooling2D()(base_model.output) # Performing Global Average Pooling\n",
        "x_batchnorm = keras.layers.BatchNormalization()(global_avg_pooling) # Performing Batch Normalization\n",
        "x_dropout = keras.layers.Dropout(0.35)(x_batchnorm) # Performing Dropout with 35% drop rate\n",
        "output_ = keras.layers.Dense(units=3,activation=\"softmax\")(x_dropout) # Output layer\n",
        "\n",
        "model_2_TL = keras.models.Model(inputs=[base_model.input],outputs=[output_])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M862wYFA-Ia6",
        "outputId": "91c2412d-0249-4497-da70-0ef1c2611215"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet101v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m171317808/171317808\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "model_2_TL.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "\n",
        "# Saving the best model using Callbacks\n",
        "callbacks_2_TL = [keras.callbacks.ModelCheckpoint(\"Best_model_2_TL.weights.h5\",monitor='val_accuracy',save_weights_only=True,save_best_only=True)]\n",
        "\n",
        "# Training the model\n",
        "train_model_2_TL = model_2_TL.fit(x=X_train_std,y=y_train,epochs=10,validation_split=0.1,batch_size=16,callbacks=callbacks_2_TL)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KAei38Y-9RZ",
        "outputId": "444bd8ae-d5ea-40cc-ea32-f14cc73fc987"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 517ms/step - accuracy: 0.6901 - loss: 0.7564 - val_accuracy: 0.9125 - val_loss: 0.2536\n",
            "Epoch 2/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 130ms/step - accuracy: 0.9243 - loss: 0.1826 - val_accuracy: 0.9125 - val_loss: 0.2013\n",
            "Epoch 3/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 152ms/step - accuracy: 0.9509 - loss: 0.1118 - val_accuracy: 0.9250 - val_loss: 0.1699\n",
            "Epoch 4/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.9771 - loss: 0.0636 - val_accuracy: 0.9125 - val_loss: 0.1633\n",
            "Epoch 5/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 128ms/step - accuracy: 0.9592 - loss: 0.1136 - val_accuracy: 0.9250 - val_loss: 0.1613\n",
            "Epoch 6/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - accuracy: 0.9737 - loss: 0.0612 - val_accuracy: 0.9625 - val_loss: 0.0957\n",
            "Epoch 7/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 131ms/step - accuracy: 0.9766 - loss: 0.0592 - val_accuracy: 0.9375 - val_loss: 0.1061\n",
            "Epoch 8/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 192ms/step - accuracy: 0.9721 - loss: 0.0764 - val_accuracy: 0.9750 - val_loss: 0.0603\n",
            "Epoch 9/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.9919 - loss: 0.0391 - val_accuracy: 0.9625 - val_loss: 0.1277\n",
            "Epoch 10/10\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 136ms/step - accuracy: 0.9757 - loss: 0.0671 - val_accuracy: 0.9625 - val_loss: 0.0768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SAVING THE MODEL"
      ],
      "metadata": {
        "id": "RV_FIvgL_MQ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving the best model obtained\n",
        "model_2_TL.save('/content/drive/MyDrive/Deep Learning Project/Model2/Best_model_2_TL.keras')"
      ],
      "metadata": {
        "id": "-D6if-mo_LjK"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}